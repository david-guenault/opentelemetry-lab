receivers:
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.logical.count:
            enabled: true      
      disk:
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
          system.memory.limit:
            enabled: true     
          system.linux.memory.available:
            enabled: true 
      network:
      load:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true      
      paging:
      processes: # process count metrics
      process: # per process cpu memory and disk io metrics
        mute_process_user_error: true
        metrics:
          process.cpu.utilization:
            enabled: true
          process.memory.utilization:
            enabled: true
          process.threads:
            enabled: true
          process.paging.faults:
            enabled: true      
      system:

  # internal telemetry
  prometheus/node-exporter:
    config:
      scrape_configs:
        - job_name: 'node_exporter'
          static_configs:
            - targets: ['localhost:9100']

  prometheus/process-exporter:
    config:
      scrape_configs:
        - job_name: 'process_exporter'
          static_configs:
            - targets: ['localhost:9256']

  prometheus/telemetry:
    config:
      scrape_configs:
      - job_name: otel-collector-metrics
        scrape_interval: 10s
        static_configs:
        - targets: ['localhost:8888']    

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024

  memory_limiter:
    check_interval: 5s
    limit_mib: 150


  # this one is required for hostmetrics
  transform/hostmetrics:
    error_mode: ignore
    metric_statements:
      - context: datapoint
        # get process command line and command line from resource attributes and put it on datapoint
        # this allow to join the target_info metric label 
        statements:
          - set(attributes["host.name"], resource.attributes["host.name"])
          - set(attributes["process.command_line"], resource.attributes["process.command_line"])
  resourcedetection/system:
    # we get the service.* metrics attributes from environment
    # caution this is not good for collectors requiring differents values
    # of service.* for differents collectors (system vs application for example)
    detectors: ["env", "system"]
    system:
      hostname_sources: ["os"]

exporters:
  debug:
    verbosity: detailed
  otlp:
    # the target endpoint for telemetry storage is also defined in an environment variable
    endpoint: ${ENDPOINT}
    tls:
      insecure: true

service:

  # internal telemetry
  telemetry:
    metrics:
      address: 0.0.0.0:8888
      level: detailed

  pipelines:

    metrics/hostmetrics:
      receivers: [hostmetrics]
      processors: [batch, memory_limiter, resourcedetection/system, transform/hostmetrics]
      exporters: [debug,otlp]

    metrics/node-exporter:
      receivers: [prometheus/node-exporter]
      processors: [batch, memory_limiter, resourcedetection/system]
      exporters: [debug,otlp]
    metrics/process-exporter:
      receivers: [prometheus/process-exporter]
      processors: [batch, memory_limiter, resourcedetection/system]
      exporters: [debug,otlp]      

    # internal telemetry
    metrics/telemetry:
      receivers: [prometheus/telemetry]
      processors: [batch, memory_limiter]
      exporters: [debug,otlp]
